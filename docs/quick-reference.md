# Quick Reference Guide

## Interactive Model Selection

All model-related make commands now feature interactive selection menus. No need to remember or type long paths!

### Chat with a Model

```bash
make chat
```

**What happens:**
1. Shows numbered list of all available models
2. You select which model to chat with
3. Starts an interactive chat session
4. Type messages and get responses
5. Use `/bye` or `Ctrl+D` to exit

**Example output:**
```
ğŸ’¬ Chat with a model

ğŸ“¦ Available models:

  [1] llama3.2:1b (1.3 GB)
  [2] mistral:7b (4.1 GB)
  [3] my-chatbot (1.3 GB) â­
  [4] my-code-helper (1.3 GB) â­

  [0] Cancel

Select a model to chat with [0-4]: 3

ğŸš€ Starting chat with: my-chatbot

ğŸ’¡ Tips:
   - Type your messages and press Enter
   - Use /bye to exit the chat
   - Use Ctrl+D to exit

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

>>> Hello! How are you?
I'm doing great, thanks for asking! How can I help you today?

>>> Tell me a joke
Why don't scientists trust atoms? Because they make up everything!

>>> /bye
ğŸ‘‹ Chat ended
```

### Create a Custom Model

```bash
make create-model
```

**What happens:**
1. Shows numbered list of all Modelfiles in `models/examples/` and `models/custom/`
2. You select by number
3. You enter a name for your new model
4. Model is created

**Example output:**
```
ğŸ”¨ Create a custom model

ğŸ“ Available Modelfiles:

  [1] examples/chatbot/Modelfile
  [2] examples/code-assistant/Modelfile
  [3] examples/creative-writer/Modelfile
  [4] examples/personal-assistant/Modelfile
  [5] examples/translator/Modelfile
  [6] custom/my-custom-bot/Modelfile

  [0] Enter custom path

Select a Modelfile [0-6]: 2
Enter name for the new model: my-code-helper
```

### Save a Model for Deployment

```bash
make save-model
```

**What happens:**
1. Shows numbered list of all models in your Ollama instance
2. You select which model to save
3. Saves Modelfile to `models/saved/`

**Example output:**
```
ğŸ’¾ Save a model for deployment

ğŸ“¦ Available models:

  [1] llama3.2:1b
  [2] mistral:7b
  [3] my-chatbot
  [4] my-code-helper
  [5] production-assistant

  [0] Enter custom name

Select a model [0-5]: 3

ğŸ’¾ Saving model: my-chatbot
Output: ./models/saved/my-chatbot.Modelfile

âœ… Model saved successfully!
```

### Deploy a Saved Model

```bash
make deploy-model
```

**What happens:**
1. Shows numbered list of saved Modelfiles in `models/saved/`
2. You select which one to deploy
3. Optionally rename it during deployment
4. Model is created in your Ollama instance

**Example output:**
```
ğŸš€ Deploy a saved model

ğŸ’¾ Available saved models:

  [1] my-chatbot.Modelfile
  [2] production-bot.Modelfile
  [3] team-assistant.Modelfile

  [0] Enter custom path

Select a saved model [0-3]: 1
Enter model name (press Enter to use filename):

ğŸš€ Deploying model: my-chatbot
âœ… Model deployed successfully!
```

## Direct Script Usage

If you prefer command-line arguments, you can still use the scripts directly:

```bash
# Create model (specify path)
bash scripts/create-custom-model.sh my-bot ./models/examples/chatbot/Modelfile

# Save model (specify name)
bash scripts/save-model.sh my-chatbot

# Deploy model (specify path)
bash scripts/deploy-model.sh ./models/saved/my-chatbot.Modelfile

# Or deploy with custom name
bash scripts/deploy-model.sh ./models/saved/my-chatbot.Modelfile renamed-bot
```

## Cheat Sheet

| Task | Command | Interactive? |
|------|---------|--------------|
| Start Ollama | `make up` | No |
| Stop Ollama | `make down` | No |
| View logs | `make logs` | No |
| Shell access | `make shell` | No |
| Pull base models | `make pull-base` | No |
| List models | `make list-models` | No |
| **Create custom model** | `make create-model` | **Yes - select Modelfile** |
| **Chat with model** | `make chat` | **Yes - select model** |
| **Save model** | `make save-model` | **Yes - select model** |
| **Deploy model** | `make deploy-model` | **Yes - select saved file** |
| Backup all models | `make backup-models` | No |
| Quick test | `make quick-test` | Yes - confirmation |
| Validation tests | `make test` | No |
| Clean up | `make clean` | Yes - confirmation |

## Directory Structure

```
models/
â”œâ”€â”€ examples/          # Pre-configured example Modelfiles
â”‚   â”œâ”€â”€ chatbot/
â”‚   â”‚   â””â”€â”€ Modelfile
â”‚   â”œâ”€â”€ code-assistant/
â”‚   â”‚   â””â”€â”€ Modelfile
â”‚   â””â”€â”€ ...
â”œâ”€â”€ custom/            # Your custom Modelfiles
â”‚   â””â”€â”€ my-bot/
â”‚       â””â”€â”€ Modelfile
â””â”€â”€ saved/             # Saved models ready for deployment
    â”œâ”€â”€ my-chatbot.Modelfile
    â””â”€â”€ production-bot.Modelfile
```

## Tips

1. **Option [0]** in any selection menu lets you enter a custom path/name
2. Saved models are stored in `models/saved/` by default
3. Backups include timestamps: `backups/models/YYYYMMDD_HHMMSS/`
4. You can still use scripts directly with paths if you prefer
5. All interactive commands can be cancelled with Ctrl+C

## Common Workflows

### Quick Test of Example Model

```bash
make up                 # Start Ollama
make pull-base          # Get base models
make create-model       # Select example, name it
make chat               # Select your model and start chatting!
```

### Deploy to Production

```bash
# On dev server:
make save-model         # Select your model

# Transfer file:
scp ./models/saved/my-model.Modelfile user@prod:/opt/ollama/models/saved/

# On prod server:
make deploy-model       # Select the transferred file
```

### Regular Backup

```bash
make backup-models      # Backs up all custom models
# Files saved to: ./backups/models/YYYYMMDD_HHMMSS/
```

### Quick Test

Test the complete workflow:

```bash
make quick-test
```

**What happens:**
1. Asks for confirmation
2. Creates a temporary test model
3. Sends a test prompt: "Hello! Can you introduce yourself in one sentence?"
4. Displays the response
5. Deletes the test model
6. Shows success summary

**Example output:**
```
ğŸ§ª Quick Model Test

This will:
  1. Create a test model from an example
  2. Send a test prompt to it
  3. Delete the test model

Continue? (y/N): y

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ Step 1/3: Creating test model 'test-chatbot-1701234567'
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Test Details:
  Base Model: llama3.2:1b
  Modelfile:  ./models/examples/chatbot/Modelfile
  Test Model: test-chatbot-1701234567

ğŸ”¨ Creating custom model: test-chatbot-1701234567
âœ… Model created successfully!

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ’¬ Step 2/3: Testing model with a prompt
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Sending test prompt: 'Hello! Can you introduce yourself in one sentence?'

Response:
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
I'm a helpful AI assistant designed to provide accurate and
clear answers to your questions.
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ—‘ï¸  Step 3/3: Cleaning up test model
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

deleted 'test-chatbot-1701234567'

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… Quick test completed successfully!
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Summary:
  âœ“ Model creation works (base: llama3.2:1b)
  âœ“ Model responds to prompts
  âœ“ Model cleanup works

You can now create your own models with:
  make create-model
```

**Note:** Output is automatically cleaned for readability (ANSI escape codes removed).
